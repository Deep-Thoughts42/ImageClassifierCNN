{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Modules and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_workers = 0\n",
    "batch_size = 36\n",
    "valid_size = 0.2\n",
    "\n",
    "# Data augmentation for train data + conversion to tensor\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(12),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "   \n",
    "])\n",
    "\n",
    "\n",
    "# Data augmentation for test data + conversion to tensor\n",
    "test_transforms= transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(0.5,))\n",
    "])\n",
    "\n",
    "\n",
    "# Picking Fashion-MNIST dataset\n",
    "train_data = datasets.FashionMNIST('Dataset', train=True, download=True, transform=train_transforms)\n",
    "test_data = datasets.FashionMNIST('Dataset', train=False, download=True, transform=test_transforms)\n",
    "\n",
    "# Finding indices for validation set\n",
    "num_train = len(train_data)\n",
    "indices = list(range(num_train))\n",
    "#Randomize indices\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "split = int(np.floor(num_train*valid_size))\n",
    "train_index, test_index = indices[split:], indices[:split]\n",
    "\n",
    "# Making samplers for training and validation batches\n",
    "train_sampler = SubsetRandomSampler(train_index)\n",
    "valid_sampler = SubsetRandomSampler(test_index)\n",
    "\n",
    "# Creating data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, num_workers=num_workers)\n",
    "\n",
    "\n",
    "# Image classes\n",
    "classes = ['T-shirt/top','Trouser','Pullover','Dress',\n",
    "           'Coat','Sandal','Shirt','Sneaker','Bag','Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ankle boot\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# imshow Taken from Udacity Intro to Machine Learning Course\n",
    "def imshow(image, ax=None, title=None, normalize=True):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        _, ax = plt.subplots()\n",
    "        \n",
    "    image = image.transpose((1, 2, 0))\n",
    "\n",
    "    if normalize:\n",
    "        mean = np.array([0.5, 0.5, 0.5])\n",
    "        std = np.array([0.5, 0.5, 0.5])\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "\n",
    "    ax.imshow(image)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.tick_params(axis='both', length=0)\n",
    "    ax.set_xticklabels('')\n",
    "    ax.set_yticklabels('')\n",
    "\n",
    "    return ax\n",
    "\n",
    "\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.numpy()\n",
    "\n",
    "\n",
    "imshow(images[0,:])\n",
    "print(classes[labels[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (conv1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "  (fc1): Linear(in_features=784, out_features=256, bias=True)\n",
      "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
      "  (fc3): Linear(in_features=128, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      "  (dropout): Dropout(p=0.2, inplace=False)\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      ")\n",
      "Will train model on GPU\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Users\\user\\Anaconda3\\lib\\site-packages\\torch\\cuda\\__init__.py:132: UserWarning: \n",
      "    Found GPU0 GeForce GTX 760 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # convolutional layers\n",
    "        self.conv1 = nn.Conv2d(1, 8, 3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(8, 16, 3, padding =1)\n",
    "        # linear layers\n",
    "        self.fc1 = nn.Linear(784, 256)\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.fc4 = nn.Linear(64, 10) \n",
    "        # dropout\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        # max pooling\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # convolutional layers with ReLU and pooling\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        # flattening the image\n",
    "        x = x.view(-1, 7*7*16)\n",
    "        # linear layers\n",
    "        x = self.dropout(F.relu(self.fc1(x)))\n",
    "        x = self.dropout(F.relu(self.fc2(x)))\n",
    "        x = self.dropout(F.relu(self.fc3(x)))\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "        \n",
    "model = Net()\n",
    "print(model)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# loss function (cross entropy loss)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\\torch\\csrc\\utils\\python_arg_parser.cpp:698: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, Number alpha)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Epoch: 1\n",
      "Training Loss: 2.303327\n",
      "Validation Loss: 2.301204\n",
      "Validation loss decreased from inf to 2.301204\n",
      "Current Epoch: 2\n",
      "Training Loss: 2.299417\n",
      "Validation Loss: 2.296374\n",
      "Validation loss decreased from 2.301204 to 2.296374\n",
      "Current Epoch: 3\n",
      "Training Loss: 2.294641\n",
      "Validation Loss: 2.290173\n",
      "Validation loss decreased from 2.296374 to 2.290173\n",
      "Current Epoch: 4\n",
      "Training Loss: 2.28691\n",
      "Validation Loss: 2.278475\n",
      "Validation loss decreased from 2.290173 to 2.278475\n",
      "Current Epoch: 5\n",
      "Training Loss: 2.271698\n",
      "Validation Loss: 2.25325\n",
      "Validation loss decreased from 2.278475 to 2.25325\n",
      "Current Epoch: 6\n",
      "Training Loss: 2.231725\n",
      "Validation Loss: 2.175184\n",
      "Validation loss decreased from 2.25325 to 2.175184\n",
      "Current Epoch: 7\n",
      "Training Loss: 2.0709\n",
      "Validation Loss: 1.822663\n",
      "Validation loss decreased from 2.175184 to 1.822663\n",
      "Current Epoch: 8\n",
      "Training Loss: 1.649778\n",
      "Validation Loss: 1.361858\n",
      "Validation loss decreased from 1.822663 to 1.361858\n",
      "Current Epoch: 9\n",
      "Training Loss: 1.378867\n",
      "Validation Loss: 1.171134\n",
      "Validation loss decreased from 1.361858 to 1.171134\n",
      "Current Epoch: 10\n",
      "Training Loss: 1.241648\n",
      "Validation Loss: 1.061616\n",
      "Validation loss decreased from 1.171134 to 1.061616\n",
      "Current Epoch: 11\n",
      "Training Loss: 1.129978\n",
      "Validation Loss: 0.968653\n",
      "Validation loss decreased from 1.061616 to 0.968653\n",
      "Current Epoch: 12\n",
      "Training Loss: 1.039131\n",
      "Validation Loss: 0.876486\n",
      "Validation loss decreased from 0.968653 to 0.876486\n",
      "Current Epoch: 13\n",
      "Training Loss: 0.95312\n",
      "Validation Loss: 0.804498\n",
      "Validation loss decreased from 0.876486 to 0.804498\n",
      "Current Epoch: 14\n",
      "Training Loss: 0.879596\n",
      "Validation Loss: 0.743189\n",
      "Validation loss decreased from 0.804498 to 0.743189\n",
      "Current Epoch: 15\n",
      "Training Loss: 0.824151\n",
      "Validation Loss: 0.699298\n",
      "Validation loss decreased from 0.743189 to 0.699298\n",
      "Current Epoch: 16\n",
      "Training Loss: 0.781424\n",
      "Validation Loss: 0.669614\n",
      "Validation loss decreased from 0.699298 to 0.669614\n",
      "Current Epoch: 17\n",
      "Training Loss: 0.756909\n",
      "Validation Loss: 0.65518\n",
      "Validation loss decreased from 0.669614 to 0.65518\n",
      "Current Epoch: 18\n",
      "Training Loss: 0.729239\n",
      "Validation Loss: 0.630462\n",
      "Validation loss decreased from 0.65518 to 0.630462\n",
      "Current Epoch: 19\n",
      "Training Loss: 0.706706\n",
      "Validation Loss: 0.616319\n",
      "Validation loss decreased from 0.630462 to 0.616319\n",
      "Current Epoch: 20\n",
      "Training Loss: 0.693982\n",
      "Validation Loss: 0.602144\n",
      "Validation loss decreased from 0.616319 to 0.602144\n",
      "Current Epoch: 21\n",
      "Training Loss: 0.68086\n",
      "Validation Loss: 0.594013\n",
      "Validation loss decreased from 0.602144 to 0.594013\n",
      "Current Epoch: 22\n",
      "Training Loss: 0.663896\n",
      "Validation Loss: 0.580354\n",
      "Validation loss decreased from 0.594013 to 0.580354\n",
      "Current Epoch: 23\n",
      "Training Loss: 0.652102\n",
      "Validation Loss: 0.572904\n",
      "Validation loss decreased from 0.580354 to 0.572904\n",
      "Current Epoch: 24\n",
      "Training Loss: 0.642563\n",
      "Validation Loss: 0.568838\n",
      "Validation loss decreased from 0.572904 to 0.568838\n",
      "Current Epoch: 25\n",
      "Training Loss: 0.629519\n",
      "Validation Loss: 0.557695\n",
      "Validation loss decreased from 0.568838 to 0.557695\n"
     ]
    }
   ],
   "source": [
    "# epochs to train for\n",
    "epochs = 25\n",
    "\n",
    "# tracks validation loss change after each epoch\n",
    "minimum_validation_loss = np.inf \n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    \n",
    "    train_loss = 0\n",
    "    valid_loss = 0\n",
    "    \n",
    "    # training steps\n",
    "    model.train()\n",
    "    for batch_index, (data, target) in enumerate(train_loader):\n",
    "        # moves tensors to GPU\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        # clears gradients\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        output = model(data)\n",
    "        # loss in batch\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass for loss gradient\n",
    "        loss.backward()\n",
    "        # update paremeters\n",
    "        optimizer.step()\n",
    "        # update training loss\n",
    "        train_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # validation steps\n",
    "    model.eval()\n",
    "    for batch_index, (data, target) in enumerate(valid_loader):\n",
    "        # moves tensors to GPU\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "        # forward pass\n",
    "        output = model(data)\n",
    "        # loss in batch\n",
    "        loss = criterion(output, target)\n",
    "        # update validation loss\n",
    "        valid_loss += loss.item()*data.size(0)\n",
    "        \n",
    "    # average loss calculations\n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    valid_loss = valid_loss/len(valid_loader.sampler)\n",
    "    \n",
    "    # Display loss statistics\n",
    "    print(f'Current Epoch: {epoch}\\nTraining Loss: {round(train_loss, 6)}\\nValidation Loss: {round(valid_loss, 6)}')\n",
    "\n",
    "    # Saving model every time validation loss decreases\n",
    "    if valid_loss <= minimum_validation_loss:\n",
    "        print(f'Validation loss decreased from {round(minimum_validation_loss, 6)} to {round(valid_loss, 6)}')\n",
    "        torch.save(model.state_dict(), 'trained_model.pt')\n",
    "        minimum_validation_loss = valid_loss\n",
    "        print('Saving New Model')\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('trained_model.pt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Network's Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.556627\n",
      "Test Accuracy of T-shirt/top: 83.09%\n",
      "Test Accuracy of Trouser: 94.64%\n",
      "Test Accuracy of Pullover: 68.33%\n",
      "Test Accuracy of Dress: 85.62%\n",
      "Test Accuracy of Coat: 70.78%\n",
      "Test Accuracy of Sandal: 81.63%\n",
      "Test Accuracy of Shirt: 23.72%\n",
      "Test Accuracy of Sneaker: 91.83%\n",
      "Test Accuracy of Bag: 92.39%\n",
      "Test Accuracy of Ankle boot: 94.04%\n",
      "Full Test Accuracy: 78.58% 6117.0 out of 7784.0\n"
     ]
    }
   ],
   "source": [
    "# tracking test loss\n",
    "test_loss = 0.0\n",
    "class_correct = list(0. for i in range(10))\n",
    "class_total = list(0. for i in range(10))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(test_loader):\n",
    "    # move tensors to GPU\n",
    "    data, target = data.cuda(), target.cuda()\n",
    "    # forward pass\n",
    "    output = model(data)\n",
    "    # batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # test loss update\n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output, 1)    \n",
    "    # compare predictions to true label\n",
    "    correct_tensor = pred.eq(target.data.view_as(pred))\n",
    "    correct = np.squeeze(correct_tensor.numpy()) if not torch.cuda.is_available() else np.squeeze(correct_tensor.cpu().numpy())\n",
    "    # calculate test accuracy for each object class\n",
    "    for i in range(28):\n",
    "        label = target.data[i]\n",
    "        class_correct[label] += correct[i].item()\n",
    "        class_total[label] += 1\n",
    "\n",
    "# average test loss\n",
    "test_loss = test_loss/len(test_loader.dataset)\n",
    "print(f'Test Loss: {round(test_loss, 6)}')\n",
    "\n",
    "for i in range(10):\n",
    "    if class_total[i] > 0:\n",
    "        print(f'Test Accuracy of {classes[i]}: {round(100*class_correct[i]/class_total[i], 2)}%')\n",
    "    else:\n",
    "        print(f'Test Accuracy of {classes[i]}s: N/A (no training examples)')\n",
    "        \n",
    "        \n",
    "print(f'Full Test Accuracy: {round(100. * np.sum(class_correct) / np.sum(class_total), 2)}% {np.sum(class_correct)} out of {np.sum(class_total)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work in Progress"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
